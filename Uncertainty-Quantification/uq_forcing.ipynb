{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_338/863777473.py:15: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pet = pd.read_csv(pet_csv_file_path)\n",
      "/tmp/ipykernel_338/863777473.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_observed_streamflow['discharge_cms'] = filtered_observed_streamflow['observation'] * 0.0283168\n",
      "/tmp/ipykernel_338/863777473.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_338/863777473.py:31: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_338/863777473.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "observed_csv_file_path = 'observed_11480390.csv'\n",
    "forcing_csv_file_path = '1148039_forcing.csv'\n",
    "pet_csv_file_path = '11480390_hourly_nldas.csv'\n",
    "\n",
    "# Create the perturbation folder if it doesn't exist\n",
    "output_folder = 'perturbation'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Read the PET CSV file into a DataFrame\n",
    "pet = pd.read_csv(pet_csv_file_path)\n",
    "\n",
    "# Read the observed streamflow CSV file into a DataFrame\n",
    "observed_streamflow = pd.read_csv(observed_csv_file_path)\n",
    "\n",
    "# Convert the 'date' column to a pandas datetime object\n",
    "observed_streamflow['date'] = pd.to_datetime(observed_streamflow['date'])\n",
    "\n",
    "# Filter the observed data for the specific date range\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2012-12-30'\n",
    "observed_mask = (observed_streamflow['date'] >= start_date) & (observed_streamflow['date'] <= end_date)\n",
    "filtered_observed_streamflow = observed_streamflow[observed_mask]\n",
    "\n",
    "# Convert discharge from cubic feet per second (cfs) to cubic meters per second (cms)\n",
    "filtered_observed_streamflow['discharge_cms'] = filtered_observed_streamflow['observation'] * 0.0283168\n",
    "filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Read the forcing data CSV file into a DataFrame\n",
    "df_forcing = pd.read_csv(forcing_csv_file_path)\n",
    "\n",
    "# Ensure the 'time' column is in datetime format\n",
    "df_forcing['time'] = pd.to_datetime(df_forcing['time'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# Filter the forcing data for the specific date range\n",
    "forcing_mask = (df_forcing['time'] >= start_date) & (df_forcing['time'] <= end_date)\n",
    "filtered_forcing = df_forcing[forcing_mask]\n",
    "filtered_columns = filtered_forcing[['APCP_surface', 'time']]\n",
    "\n",
    "# Filter PET data like observation and forcing\n",
    "# Convert the 'date' column to a pandas datetime object\n",
    "pet['date'] = pd.to_datetime(pet['date'])\n",
    "\n",
    "# Filter the PET data for the specific date range\n",
    "pet_mask = (pet['date'] >= start_date) & (pet['date'] <= end_date)\n",
    "filtered_pet = pet[pet_mask]\n",
    "\n",
    "# Extract only the 'date' and 'potential_evaporation' columns\n",
    "filtered_pet = filtered_pet[['date', 'potential_evaporation']]\n",
    "filtered_pet = filtered_pet[['potential_evaporation']]\n",
    "\n",
    "p_data = pd.concat([filtered_columns, filtered_pet], axis=1)\n",
    "p_data.set_index('time', inplace=True)\n",
    "\n",
    "# Example error value\n",
    "err = 0.15  # Replace with the actual error value\n",
    "\n",
    "# Extract the data\n",
    "apcp_surface = p_data['APCP_surface'].values\n",
    "pet = p_data['potential_evaporation'].values\n",
    "\n",
    "# Number of time steps (nda) and samples (nSample)\n",
    "nda = len(apcp_surface)\n",
    "nSample = 25  # Replace with the actual number of samples\n",
    "\n",
    "# Create arrays to hold the perturbed values\n",
    "pr_apcp = np.zeros((nda, nSample))\n",
    "pr_pet = np.zeros((nda, nSample))\n",
    "\n",
    "# Perturb the APCP_surface values using a lognormal distribution\n",
    "for t in range(nda):\n",
    "    pr_apcp[t, :] = np.random.lognormal(mean=np.log(apcp_surface[t] + 1e-10), sigma=err, size=nSample)  # Adding a small value to avoid log(0)\n",
    "\n",
    "# Perturb the potential_evaporation (PET) values using a normal distribution\n",
    "for t in range(nda):\n",
    "    pr_pet[t, :] = pet[t] + np.random.randn(nSample) * pet[t] * err\n",
    "\n",
    "# Save each sample to a separate CSV file in the perturbation folder\n",
    "for i in range(nSample):\n",
    "    sample_data = pd.DataFrame({\n",
    "        'time': p_data.index,\n",
    "        'APCP_surface': pr_apcp[:, i],\n",
    "        'potential_evaporation': pr_pet[:, i]\n",
    "    })\n",
    "    sample_data.to_csv(os.path.join(output_folder, f'sample_{i + 1}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_338/428349675.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_observed_streamflow['discharge_cms'] = filtered_observed_streamflow['observation'] * 0.0283168\n",
      "/tmp/ipykernel_338/428349675.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_338/428349675.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_338/428349675.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation for: perturbation/sample_15.csv\n",
      "Running simulation for: perturbation/sample_9.csv\n",
      "Running simulation for: perturbation/sample_19.csv\n",
      "Running simulation for: perturbation/sample_22.csv\n",
      "Running simulation for: perturbation/sample_7.csv\n",
      "Running simulation for: perturbation/sample_5.csv\n",
      "Running simulation for: perturbation/sample_2.csv\n",
      "Running simulation for: perturbation/sample_20.csv\n",
      "Running simulation for: perturbation/sample_16.csv\n",
      "Running simulation for: perturbation/sample_6.csv\n",
      "Running simulation for: perturbation/sample_11.csv\n",
      "Running simulation for: perturbation/sample_23.csv\n",
      "Running simulation for: perturbation/sample_21.csv\n",
      "Running simulation for: perturbation/sample_12.csv\n",
      "Running simulation for: perturbation/sample_4.csv\n",
      "Running simulation for: perturbation/sample_10.csv\n",
      "Running simulation for: perturbation/sample_25.csv\n",
      "Running simulation for: perturbation/sample_13.csv\n",
      "Running simulation for: perturbation/sample_14.csv\n",
      "Running simulation for: perturbation/sample_8.csv\n",
      "Running simulation for: perturbation/sample_17.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import bmi_cfe\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure the directory for simulation results exists\n",
    "os.makedirs('simulation_results', exist_ok=True)\n",
    "\n",
    "# List all CSV files\n",
    "csv_files = glob.glob('perturbation/sample_*.csv')\n",
    "\n",
    "# Filter the observed data for the specific date range\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2012-12-30'\n",
    "observed_mask = (observed_streamflow['date'] >= start_date) & (observed_streamflow['date'] <= end_date)\n",
    "filtered_observed_streamflow = observed_streamflow[observed_mask]\n",
    "\n",
    "# Convert discharge from cubic feet per second (cfs) to cubic meters per second (cms)\n",
    "filtered_observed_streamflow['discharge_cms'] = filtered_observed_streamflow['observation'] * 0.0283168\n",
    "filtered_observed_streamflow['discharge_cms'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Save the filtered and converted observed data to a new CSV file\n",
    "filtered_observed_output_file_path = 'filtered_observed_converted.csv'\n",
    "filtered_observed_streamflow.to_csv(filtered_observed_output_file_path, index=False)\n",
    "discharge_usgs = filtered_observed_streamflow['discharge_cms']\n",
    "time_index_observed = pd.to_datetime(filtered_observed_streamflow['date'])\n",
    "df2 = discharge_usgs.values.flatten()\n",
    "\n",
    "# Initialize an empty DataFrame to store all simulation results\n",
    "all_simulations_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Running simulation for: {csv_file}\")  # Print the name of the simulation file\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filter the necessary columns\n",
    "    filtered_forcing = data[['time', 'APCP_surface']]\n",
    "    filtered_pet = data['potential_evaporation']\n",
    "\n",
    "    # Initialize the CFE instance\n",
    "    cfe_instance = bmi_cfe.BMI_CFE('./best_config_Perturb.json')\n",
    "    cfe_instance.initialize()\n",
    "\n",
    "    # Get output variable names\n",
    "    outputs = cfe_instance.get_output_var_names()\n",
    "    output_lists = {output: [] for output in outputs}\n",
    "\n",
    "    # Run the model for each precipitation value in the filtered forcing data\n",
    "    for precip, pet in zip(filtered_forcing['APCP_surface'], filtered_pet):\n",
    "        cfe_instance.set_value('atmosphere_water__time_integral_of_precipitation_mass_flux', precip)\n",
    "        cfe_instance.set_value('water_potential_evaporation_flux', pet / 1000 / 3600)\n",
    "\n",
    "        cfe_instance.update()\n",
    "\n",
    "        for output in outputs:\n",
    "            output_lists[output].append(cfe_instance.get_value(output))\n",
    "\n",
    "    # Finalize the model\n",
    "    cfe_instance.finalize(print_mass_balance=False)\n",
    "\n",
    "    # Convert the output lists to a DataFrame\n",
    "    output_df = pd.DataFrame(output_lists)\n",
    "    output_df['time'] = filtered_forcing['time']\n",
    "    output_df['csv_file'] = os.path.basename(csv_file)\n",
    "    \n",
    "    # Append the output DataFrame to the consolidated DataFrame\n",
    "    all_simulations_df = pd.concat([all_simulations_df, output_df], ignore_index=True)\n",
    "\n",
    "# Save the consolidated DataFrame to a CSV file\n",
    "all_simulations_df.to_csv('simulation_results/all_simulations.csv', index=False)\n",
    "\n",
    "# Adjust the runoff volume flux by dividing by 3600 for plotting\n",
    "all_simulations_df['land_surface_water__runoff_volume_flux'] = all_simulations_df['land_surface_water__runoff_volume_flux'] / 3600\n",
    "\n",
    "# Calculate the average of all simulations for each time step\n",
    "average_simulation = all_simulations_df.groupby('time')['land_surface_water__runoff_volume_flux'].mean()\n",
    "\n",
    "# Calculate the min and max for the shaded area\n",
    "simulation_grouped = all_simulations_df.groupby('time')['land_surface_water__runoff_volume_flux']\n",
    "min_simulation = simulation_grouped.min()\n",
    "max_simulation = simulation_grouped.max()\n",
    "\n",
    "# Convert time index for plotting\n",
    "time_index_average_simulation = pd.to_datetime(average_simulation.index)\n",
    "time_index_min_max_simulation = pd.to_datetime(min_simulation.index)\n",
    "\n",
    "# Plot the observed and all simulated discharges with shaded area\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_index_observed, df2, label='Observed Discharge (USGS)', color='blue')\n",
    "plt.fill_between(time_index_min_max_simulation, min_simulation, max_simulation, color='dimgrey', alpha=0.3, label='Predictive Interval (99%)')\n",
    "plt.plot(time_index_average_simulation, average_simulation, linestyle='--', color='red', label='Average Simulation (CFE)' )\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (cms)')\n",
    "plt.title('Gauge #11480390')\n",
    "plt.legend()\n",
    "plt.savefig('ensemble-2012')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'average_simulation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43maverage_simulation\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate performance metrics\u001b[39;00m\n\u001b[1;32m      4\u001b[0m NSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (np\u001b[38;5;241m.\u001b[39msum((df1 \u001b[38;5;241m-\u001b[39m df2) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum((df2 \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(df2)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'average_simulation' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = np.array(average_simulation)\n",
    "\n",
    "# Calculate performance metrics\n",
    "NSE = 1 - (np.sum((df1 - df2) ** 2) / np.sum((df2 - np.mean(df2)) ** 2))\n",
    "PCC = np.sum((df1 - np.mean(df1)) * (df2 - np.mean(df2))) / np.sqrt(np.sum((df1 - np.mean(df1)) ** 2) * np.sum((df2 - np.mean(df2)) ** 2))\n",
    "KGE = 1 - np.sqrt((PCC - 1) ** 2 + ((np.mean(df2) / np.mean(df1)) - 1) ** 2 + ((np.std(df2) / np.std(df1)) - 1) ** 2)\n",
    "MSE = np.mean((df1 - df2) ** 2)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f'Nash-Sutcliffe Efficiency (NSE): {NSE}')\n",
    "print(f'Pearson Correlation Coefficient (PCC): {PCC}')\n",
    "print(f'Kling-Gupta Efficiency (KGE): {KGE}')\n",
    "print(f'Mean Squared Error (MSE): {MSE}')\n",
    "print(f'Root Mean Squared Error (RMSE): {RMSE}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_index_average_simulation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m time_index_observed_plot \u001b[38;5;241m=\u001b[39m time_index_observed[plot_mask]\n\u001b[1;32m      5\u001b[0m df2_plot \u001b[38;5;241m=\u001b[39m df2[plot_mask]\n\u001b[0;32m----> 6\u001b[0m plot_mask_simulation \u001b[38;5;241m=\u001b[39m (\u001b[43mtime_index_average_simulation\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m plot_start_date) \u001b[38;5;241m&\u001b[39m (time_index_average_simulation \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m plot_end_date)\n\u001b[1;32m      7\u001b[0m time_index_average_simulation_plot \u001b[38;5;241m=\u001b[39m time_index_average_simulation[plot_mask_simulation]\n\u001b[1;32m      8\u001b[0m average_simulation_plot \u001b[38;5;241m=\u001b[39m average_simulation[plot_mask_simulation]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_index_average_simulation' is not defined"
     ]
    }
   ],
   "source": [
    "plot_start_date = '2012-03-27'\n",
    "plot_end_date = '2012-03-31'\n",
    "plot_mask = (time_index_observed >= plot_start_date) & (time_index_observed <= plot_end_date)\n",
    "time_index_observed_plot = time_index_observed[plot_mask]\n",
    "df2_plot = df2[plot_mask]\n",
    "plot_mask_simulation = (time_index_average_simulation >= plot_start_date) & (time_index_average_simulation <= plot_end_date)\n",
    "time_index_average_simulation_plot = time_index_average_simulation[plot_mask_simulation]\n",
    "average_simulation_plot = average_simulation[plot_mask_simulation]\n",
    "time_index_min_max_simulation_plot = time_index_min_max_simulation[plot_mask_simulation]\n",
    "min_simulation_plot = min_simulation[plot_mask_simulation]\n",
    "max_simulation_plot = max_simulation[plot_mask_simulation]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_index_observed_plot, df2_plot, label='Observed Discharge (USGS)', color='blue')\n",
    "plt.fill_between(time_index_min_max_simulation_plot, min_simulation_plot, max_simulation_plot, color='gray', alpha=0.3, label='Predictive Interval(99%)')\n",
    "plt.plot(time_index_average_simulation_plot, average_simulation_plot, linestyle='--', color='red', label='Average simulation (CFE) ')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Discharge (cms)')\n",
    "plt.title('Gauge #11480390')\n",
    "plt.legend()\n",
    "plt.savefig('filtered_ensemble_peak')\n",
    "plt.show()\n",
    "\n",
    "def nash_sutcliffe_efficiency(observed, simulated):\n",
    "    return 1 - np.sum((observed - simulated) ** 2) / np.sum((observed - np.mean(observed)) ** 2)\n",
    "\n",
    "def kling_gupta_efficiency(observed, simulated):\n",
    "    cc = np.corrcoef(observed, simulated)[0, 1]\n",
    "    alpha = np.std(simulated) / np.std(observed)\n",
    "    beta = np.mean(simulated) / np.mean(observed)\n",
    "    kge = 1 - np.sqrt((cc - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "    return kge\n",
    "rmse = np.sqrt(mean_squared_error(observed_values, simulated_values))\n",
    "nse = nash_sutcliffe_efficiency(observed_values, simulated_values)\n",
    "kge = kling_gupta_efficiency(observed_values, simulated_values)\n",
    "\n",
    "print(f'Root Mean Square Error (RMSE): {rmse}')\n",
    "print(f'Nash-Sutcliffe Efficiency (NSE): {nse}')\n",
    "print(f'Kling-Gupta Efficiency (KGE): {kge}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "01d3253c1168740d9ef2f293e3773b12c83382be17989c0cb85e17b3e40bf904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
